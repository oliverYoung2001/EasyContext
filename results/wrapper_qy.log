+ export CUDA_DEVICE_MAX_CONNECTIONS=32
+ CUDA_DEVICE_MAX_CONNECTIONS=32
+ srun -p rag -N 1 --ntasks-per-node=4 --gres=gpu:4 --mem 256G -K -w g3017 -c 16 ./scripts/bench_ring_attn.sh python bench_ring_attn.py
srun: job 12679 queued and waiting for resources
srun: job 12679 has been allocated resources
torch distributed is already initialized, skipping initialization ...
************ Finish sequence pralell group Initialization. ***********
Nh=32, S=4096
# orchestrated_attn_func, fwd
(0, 0, 0, 0, 0): 0.000e+00, 1.150e-04, 1.150e-04
(0, 0, 1, 0, 3): 1.545e-04, 1.150e-04, 2.695e-04
(0, 0, 1, 1, 1): 0.000e+00, 1.150e-04, 1.150e-04
(0, 0, 2, 0, 2): 2.871e-04, 1.150e-04, 4.021e-04
(0, 0, 2, 1, 2): 1.721e-04, 1.150e-04, 2.871e-04
(0, 0, 2, 2, 2): 0.000e+00, 1.150e-04, 1.150e-04
(0, 0, 3, 0, 0): 1.150e-04, 1.150e-04, 2.300e-04
(0, 0, 3, 1, 1): 1.150e-04, 1.150e-04, 2.300e-04
(0, 0, 3, 2, 0): 2.300e-04, 1.150e-04, 3.450e-04
(0, 0, 3, 3, 3): 2.695e-04, 1.150e-04, 3.845e-04
(0, 0, 1, 1, 3, 'i', 'r'): 0.000e+00, 5.706e-05, 5.706e-05
(0, 0, 1, 3, 1, 'o', 'r'): 2.695e-04, 5.706e-05, 3.266e-04
(0, 0, 3, 3, 0, 'i', 'r'): 0.000e+00, 5.706e-05, 5.706e-05
(0, 0, 3, 0, 3, 'o', 'r'): 3.450e-04, 5.706e-05, 4.021e-04
(0, 0, 3, 3, 1, 'i', 'r'): 5.706e-05, 5.706e-05, 1.141e-04
(0, 0, 3, 1, 3, 'o', 'r'): 2.879e-04, 5.706e-05, 3.450e-04
(0, 0, 0, 0, 3, 'i', 'c'): 5.706e-05, 9.746e-05, 1.545e-04
(0, 0, 0, 0, 2, 'i', 'c'): 1.721e-04, 9.746e-05, 2.695e-04
(0, 0, 1, 1, 2, 'i', 'c'): 7.460e-05, 9.746e-05, 1.721e-04
(0, 0, 2, 2, 0, 'i', 'c'): 5.706e-05, 9.746e-05, 1.545e-04
Streams:
gpu0, comp: 3
(0, 0, 0, 0, 0): 0.000e+00, 1.150e-04, 1.150e-04
(0, 0, 3, 0, 0): 1.150e-04, 1.150e-04, 2.300e-04
(0, 0, 3, 2, 0): 2.300e-04, 1.150e-04, 3.450e-04
gpu0, send: 3
(0, 0, 0, 0, 3, 'i', 'c'): 5.706e-05, 9.746e-05, 1.545e-04
(0, 0, 0, 0, 2, 'i', 'c'): 1.721e-04, 9.746e-05, 2.695e-04
(0, 0, 3, 0, 3, 'o', 'r'): 3.450e-04, 5.706e-05, 4.021e-04
gpu0, recv: 2
(0, 0, 3, 3, 0, 'i', 'r'): 0.000e+00, 5.706e-05, 5.706e-05
(0, 0, 2, 2, 0, 'i', 'c'): 5.706e-05, 9.746e-05, 1.545e-04
gpu1, comp: 2
(0, 0, 1, 1, 1): 0.000e+00, 1.150e-04, 1.150e-04
(0, 0, 3, 1, 1): 1.150e-04, 1.150e-04, 2.300e-04
gpu1, send: 3
(0, 0, 1, 1, 3, 'i', 'r'): 0.000e+00, 5.706e-05, 5.706e-05
(0, 0, 1, 1, 2, 'i', 'c'): 7.460e-05, 9.746e-05, 1.721e-04
(0, 0, 3, 1, 3, 'o', 'r'): 2.879e-04, 5.706e-05, 3.450e-04
gpu1, recv: 2
(0, 0, 3, 3, 1, 'i', 'r'): 5.706e-05, 5.706e-05, 1.141e-04
(0, 0, 1, 3, 1, 'o', 'r'): 2.695e-04, 5.706e-05, 3.266e-04
gpu2, comp: 3
(0, 0, 2, 2, 2): 0.000e+00, 1.150e-04, 1.150e-04
(0, 0, 2, 1, 2): 1.721e-04, 1.150e-04, 2.871e-04
(0, 0, 2, 0, 2): 2.871e-04, 1.150e-04, 4.021e-04
gpu2, send: 1
(0, 0, 2, 2, 0, 'i', 'c'): 5.706e-05, 9.746e-05, 1.545e-04
gpu2, recv: 2
(0, 0, 1, 1, 2, 'i', 'c'): 7.460e-05, 9.746e-05, 1.721e-04
(0, 0, 0, 0, 2, 'i', 'c'): 1.721e-04, 9.746e-05, 2.695e-04
gpu3, comp: 2
(0, 0, 1, 0, 3): 1.545e-04, 1.150e-04, 2.695e-04
(0, 0, 3, 3, 3): 2.695e-04, 1.150e-04, 3.845e-04
gpu3, send: 3
(0, 0, 3, 3, 0, 'i', 'r'): 0.000e+00, 5.706e-05, 5.706e-05
(0, 0, 3, 3, 1, 'i', 'r'): 5.706e-05, 5.706e-05, 1.141e-04
(0, 0, 1, 3, 1, 'o', 'r'): 2.695e-04, 5.706e-05, 3.266e-04
gpu3, recv: 4
(0, 0, 1, 1, 3, 'i', 'r'): 0.000e+00, 5.706e-05, 5.706e-05
(0, 0, 0, 0, 3, 'i', 'c'): 5.706e-05, 9.746e-05, 1.545e-04
(0, 0, 3, 1, 3, 'o', 'r'): 2.879e-04, 5.706e-05, 3.450e-04
(0, 0, 3, 0, 3, 'o', 'r'): 3.450e-04, 5.706e-05, 4.021e-04
objective=4.021e-04
suffix: _alg12, mfu: 66.639 Tflops/s, hfu: 66.639 Tflops/s, 1939.446 iter/s, 5.156e-04 s/iter, (2.906, 0.052, 0.103) sec
+ set +x
