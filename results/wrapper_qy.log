+ export CUDA_DEVICE_MAX_CONNECTIONS=1
+ CUDA_DEVICE_MAX_CONNECTIONS=1
+ srun -p rag -N 1 --ntasks-per-node=8 --gres=gpu:8 --mem 256G -K -c 16 ./scripts/bench_ring_attn.sh python bench_ring_attn.py
srun: job 3280 queued and waiting for resources
srun: job 3280 has been allocated resources
torch distributed is already initialized, skipping initialization ...
************ Finish sequence pralell group Initialization. ***********
S=131072
# overlapped_hierarchy_attn_func, fwd
mfu: 136.478 Tflops/s, hfu: 136.478 Tflops/s, 7.758 iter/s, 12.890 sec
+ set +x
